### 人工智能的数学基础

#### 2.1导数

导数与函数单调性的关系、极值定理、导数与函数凹凸性的关系（二阶导数）大于零为凸函数、小于零为凹函数

#### 2.5向量的范数

范数就是将向量变成了一个标量

单位向量的二范数就是1

#### 2.6矩阵

逆矩阵： 

有一个方阵

AB = I 

BA = I

可以用来求线性方程组： Ax = b  x = A-1b

(用代数余子式或者高斯消元法来解矩阵的逆矩阵)

#### 行列式

方阵才能求行列式

#### 梯度  

对所有自变量的偏导数构成的一个向量

#### 雅可比矩阵

一阶偏导数构成的矩阵；

发明他的目的是为了简化求导公式

#### Hessian矩阵

二阶混合偏导数，与函数的凹凸性质有关

矩阵正定：凸；矩阵负定：凹函数

矩阵正定 ：对任意一个XTAx都大于零

#### 二次型

#### 最优化中的基本概念

最优化问题：通常情况下，最优化问题统一表述成求极小值问题；

目标函数

优化变量

可行域

等式约束

不等式约束

局部极小值

全局极小值

为什么要使用迭代法：

有些时候直接求解导数等于零或者梯度等于零的方程/方程组难度是极大的（求解超越方程）；所以只能近似求解；

当然，迭代法不光可以用来求函数的极值，也可以用来求方程组的解等；

#### 梯度下降法（数字优化）

 负梯度方向下降的最快；

1.初始值的设定

2.步长的选择

3.迭代终止的判定规则

#### 牛顿法

#### 坐标下降法







